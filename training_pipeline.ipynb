{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "import transformers\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "from torch.optim import lr_scheduler, Optimizer\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "from transformers import AutoModel, AutoTokenizer, BatchEncoding\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from typing import Optional\n",
    "\n",
    "from typing import Tuple, List, Union\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(Dataset):\n",
    "    def __init__(self, qa_data: pd.DataFrame):\n",
    "        assert 'QuestionTitle' in qa_data.columns, \"DataFrame must contain 'QuestionTitle' column\"\n",
    "        assert 'QuestionBody' in qa_data.columns, \"DataFrame must contain 'QuestionBody' column\"\n",
    "        assert 'Answer' in qa_data.columns, \"DataFrame must contain 'Answer' column\"\n",
    "        \n",
    "        self.qa_data = qa_data\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.qa_data['QuestionTitle'])\n",
    "    \n",
    "    def __getitem__(self, index: int) -> dict:\n",
    "        # Access the data directly using iloc, which is more memory-efficient\n",
    "        return {\n",
    "            'title': self.qa_data.iloc[index]['QuestionTitle'],\n",
    "            'body': self.qa_data.iloc[index]['QuestionBody'],\n",
    "            'answers': self.qa_data.iloc[index]['Answer']\n",
    "        }\n",
    "        \n",
    "class TrainValidatePipeline:\n",
    "    def __init__(self, q_model: AutoModel, a_model: AutoModel, tokenizer: AutoTokenizer, optimizer: Optimizer, scheduler: Optional[_LRScheduler], device: torch.device ='cpu'):\n",
    "        self.q_model = q_model\n",
    "        self.a_model = a_model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "\n",
    "    def tokenize_qa_batch(self, q_titles: List[str], q_bodies: List[str], answers: List[str], max_length: int = 64) -> Tuple[BatchEncoding, BatchEncoding]:\n",
    "\n",
    "        q_batch = self.tokenizer(text = q_titles, text_pair = q_bodies, padding =\"longest\", max_length = max_length, truncation = True, return_tensors =\"pt\")\n",
    "        a_batch = self.tokenizer(text = answers, padding= \"longest\", max_length = max_length, truncation = True, return_tensors = \"pt\")\n",
    "\n",
    "        q_batch = {k: v.to(self.device) for k, v in q_batch.items()}\n",
    "        a_batch = {k: v.to(self.device) for k, v in a_batch.items()}\n",
    "\n",
    "        return q_batch, a_batch\n",
    "\n",
    "    def get_class_output(self, model: AutoModel, batch: BatchEncoding) -> BaseModelOutput:\n",
    "        output = model(**batch)\n",
    "        output = output.last_hidden_state\n",
    "        return output[:,0,:]\n",
    "\n",
    "    def inbatch_negative_sampling(self, Q: Tensor, P: Tensor) -> Tensor:\n",
    "        # Q: Tensor of shape: N question titles + bodies, E embedding dimension\n",
    "        # P: Tensor of shape: N passages, E embedding dimension\n",
    "\n",
    "        S = (Q @ P.transpose(0,1)).to(self.device)\n",
    "\n",
    "        return S\n",
    "\n",
    "\n",
    "    def contrastive_loss_criterion(self, S: Tensor, labels: Tensor = None) -> Tensor:\n",
    "        # First Calculate the log softmax as per the paper's definition\n",
    "        softmax_scores = F.log_softmax(S, dim = 1)\n",
    "        if labels == None:\n",
    "            labels = torch.arange(len(S)).to(self.device)\n",
    "\n",
    "        loss = F.nll_loss(softmax_scores, labels.to(self.device))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def get_topk_indices(self, Q: Tensor, P: Tensor, k: int = None) -> Tuple[Tensor, Tensor]:\n",
    "        S = self.inbatch_negative_sampling(Q, P)\n",
    "        if k == None:\n",
    "            k = len(S)\n",
    "        \n",
    "        scores, indices = torch.topk(S, k)\n",
    "\n",
    "        return indices, scores\n",
    "\n",
    "    def select_by_indices(self, indices: Tensor, passages: List[str]) -> List[List[str]]:\n",
    "        return [[passages[idx] for idx in index] for index in indices]\n",
    "\n",
    "    def embed_passages(self, passages: List[str], max_length: int = 512) -> BaseModelOutput:\n",
    "        return self.__embed_text(passages, self.a_model, self.tokenizer, max_length, as_pair=False)\n",
    "\n",
    "    def embed_questions(self, titles: List[str], bodies: List[str], max_length: int = 512) -> BaseModelOutput:\n",
    "        return self.__embed_text((titles, bodies), self.q_model, self.tokenizer, max_length, as_pair=True)\n",
    "\n",
    "    def __embed_text(self, texts: Union[List[str], Tuple[List[str], List[str]]], model : AutoModel, tokenizer : AutoTokenizer, max_length : int = 512, as_pair : bool = False) -> BaseModelOutput:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            if as_pair:\n",
    "                encoded_batch = tokenizer(\n",
    "                    text=texts[0], text_pair=texts[1],\n",
    "                    max_length=max_length, truncation=True,\n",
    "                    padding='max_length', return_tensors='pt'\n",
    "                )\n",
    "            else:\n",
    "                encoded_batch = tokenizer(\n",
    "                    text=texts,\n",
    "                    max_length=max_length, truncation=True,\n",
    "                    padding='max_length', return_tensors='pt'\n",
    "                )\n",
    "            encoded_batch = {k: v.to(self.device) for k, v in encoded_batch.items()}\n",
    "            outputs = model(**encoded_batch)\n",
    "            return outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "    def train(self, train_loader: DataLoader, valid_loader : DataLoader, epochs : int) ->  Tuple[List[float], List[float], List[float], List[float]]:\n",
    "        training_loss = []\n",
    "        validation_loss = []\n",
    "        validation_recall = []\n",
    "        validation_mrr = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.q_model.train()\n",
    "            self.a_model.train()\n",
    "            total_train_loss = 0\n",
    "\n",
    "            for train_batch in tqdm(train_loader):\n",
    "                q_titles = train_batch['title']\n",
    "                q_bodies = train_batch['body']\n",
    "                answers = train_batch['answers']\n",
    "\n",
    "                # Tokenize and embed the batch data\n",
    "                q_batch, a_batch = self.tokenize_qa_batch(q_titles, q_bodies, answers)\n",
    "                q_out = self.get_class_output(self.q_model, q_batch)\n",
    "                a_out = self.get_class_output(self.a_model, a_batch)\n",
    "\n",
    "                S = self.inbatch_negative_sampling(q_out, a_out)\n",
    "                loss = self.contrastive_loss_criterion(S)\n",
    "                total_train_loss += loss.item()\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            \n",
    "            self.scheduler.step()\n",
    "            average_train_loss = total_train_loss / len(train_loader)\n",
    "            print(f\"Epoch: {epoch+1} | Average training loss per sample: {average_train_loss}\")\n",
    "            training_loss.append(average_train_loss)\n",
    "\n",
    "            # Perform validation\n",
    "            avg_valid_loss, recall_k, mrr = self.validate(valid_loader)\n",
    "            validation_loss.append(avg_valid_loss)\n",
    "            validation_recall.append(recall_k)\n",
    "            validation_mrr.append(mrr)\n",
    "\n",
    "        return training_loss, validation_loss, validation_recall, validation_mrr\n",
    "\n",
    "    def validate(self, valid_loader : DataLoader) -> Tuple[float, float, float]:\n",
    "        self.q_model.eval()\n",
    "        self.a_model.eval()\n",
    "        total_valid_loss = 0\n",
    "        all_retrieved_indices = []\n",
    "        all_true_indices = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for valid_batch in tqdm(valid_loader):\n",
    "                q_titles = valid_batch['title']\n",
    "                q_bodies = valid_batch['body']\n",
    "                answers = valid_batch['answers']\n",
    "\n",
    "                # Embed questions and answers\n",
    "                Q = self.embed_questions(titles=q_titles, bodies=q_bodies, max_length=512)\n",
    "                P = self.embed_passages(passages=answers, max_length=512)\n",
    "\n",
    "                S = self.inbatch_negative_sampling(Q, P)\n",
    "                loss = self.contrastive_loss_criterion(S)\n",
    "                total_valid_loss += loss.item()\n",
    "\n",
    "                indices, _ = self.get_topk_indices(Q, P, k=5)\n",
    "                true_indices = list(range(len(Q)))\n",
    "                all_retrieved_indices.extend(indices.cpu().tolist())\n",
    "                all_true_indices.extend(true_indices)\n",
    "\n",
    "        average_valid_loss = total_valid_loss / len(valid_loader)\n",
    "        recall_k = self.recall_at_k(all_retrieved_indices, all_true_indices, k=5)\n",
    "        mrr = self.mean_reciprocal_rank(all_retrieved_indices, all_true_indices)\n",
    "\n",
    "        print(f\"Validation | Average loss per sample: {average_valid_loss}\")\n",
    "        print(f\"Validation | Recall@k: {recall_k}\")\n",
    "        print(f\"Validation | MRR: {mrr}\")\n",
    "\n",
    "        return average_valid_loss, recall_k, mrr\n",
    "    \n",
    "    def recall_at_k(self, retrieved_indices: List[List[int]], true_indices: List[int], k : int) -> float:\n",
    "        hit = 0\n",
    "        for true,retrieved in zip(true_indices, retrieved_indices):\n",
    "            top_k_set = set(retrieved[:k])\n",
    "            if true in top_k_set:\n",
    "                hit += 1\n",
    "        total = len(true_indices)\n",
    "\n",
    "        return hit / total\n",
    "\n",
    "    def mean_reciprocal_rank(self, retrieved_indices: List[List[int]], true_indices: List[int]) -> float:\n",
    "        hit = 0\n",
    "        for true,retrieved in zip(true_indices, retrieved_indices):\n",
    "            try:\n",
    "                rank = 1 + retrieved.index(true)\n",
    "                hit += 1 / rank\n",
    "            except ValueError:\n",
    "                continue\n",
    "        total = len(true_indices)\n",
    "        return hit / total\n",
    "    \n",
    "    \n",
    "    \n",
    "def load_models_and_tokenizer(q_name: str, a_name: str, t_name: str, device: torch.device ='cpu') -> Tuple[AutoModel, AutoModel, AutoTokenizer]:\n",
    "    q_enc = AutoModel.from_pretrained(q_name).to(device)\n",
    "    a_enc = AutoModel.from_pretrained(a_name).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(t_name)\n",
    "    \n",
    "    return q_enc, a_enc, tokenizer\n",
    "\n",
    "def enableMultiGPU(model: AutoModel, multi_gpu: bool):\n",
    "    if multi_gpu:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "        import os\n",
    "        os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "        \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Reproducibility\n",
    "random.seed(2024)\n",
    "torch.manual_seed(2024)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "bsize = 128\n",
    "n_epoch = 20\n",
    "lr = 5e-5\n",
    "name = 'google/electra-small-discriminator'\n",
    "step_size = 8\n",
    "gamma = 0.8\n",
    "multi_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load File\n",
    "qa_data = dict(\n",
    "    train = pd.read_csv('qa/train.csv'),\n",
    "    valid = pd.read_csv('qa/validation.csv'),\n",
    "    answers = pd.read_csv('qa/answers.csv'),\n",
    "    test = pd.read_csv('qa/test.csv'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "train_dataset = QADataset(qa_data['train'])\n",
    "valid_dataset = QADataset(qa_data['valid'])                      \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = bsize, shuffle = True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size = bsize, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Training and Validation Pipeline\n",
    "q_enc, a_enc, tokenizer = load_models_and_tokenizer(q_name = name, a_name = name, t_name = name, device = device)\n",
    "q_enc = enableMultiGPU(q_enc, multi_gpu)\n",
    "a_enc = enableMultiGPU(a_enc, multi_gpu)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(chain(q_enc.parameters(), a_enc.parameters()), lr= lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer,step_size = step_size, gamma = gamma)\n",
    "\n",
    "pipeline = TrainValidatePipeline(q_enc, a_enc, tokenizer, optimizer, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Training and Validation at the same time\n",
    "t_l, v_l, v_r, v_mrr = pipeline.train(train_loader, valid_loader, n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the graph:\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 4))\n",
    "ax1.plot(t_l, label = \"Training Loss\")  \n",
    "ax1.plot(v_l, label = \"Validation Loss\")\n",
    "ax1.set_title('Loss vs. Epoch')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(v_r, label = \"Validation Recall\")\n",
    "ax2.plot(v_mrr, label = \"Validaion Mean Reciprocal Rank\")\n",
    "ax2.set_title('Validation Results')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Result')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model:\n",
    "q_enc = q_enc.to('cpu')\n",
    "a_enc = a_enc.to('cpu')\n",
    "torch.save(q_enc.state_dict(), \"model/q_encoder_model.bin\")\n",
    "torch.save(a_enc.state_dict(), \"model/a_encoder_model.bin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
